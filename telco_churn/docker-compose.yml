services:
  train:
    image: telco-churn
    env_file:
      - .env.dev
      - .env.prod
    volumes:
      - ./config:/app/config
      - ./data:/app/data
      - ./models:/app/models
      - ./output:/app/output
      - ./mlruns:/app/mlruns
      - ./mlflow.db:/app/mlflow.db
    environment:
      MLFLOW_TRACKING_URI: sqlite:///app/mlflow.db
      MLFLOW_ARTIFACT_URI: file:///app/mlruns
      CONFIG_FILE: /app/config/config_train_dev.yaml
    command: sh -c "poetry run train-telco --config ${CONFIG_FILE}"

  inference:
    image: telco-churn
    env_file:
      - .env.dev
      - .env.prod
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./output:/app/output
    command: poetry run inference-pipeline

  web:
    image: telco-churn
    env_file:
      - .env.dev
      - .env.prod
    volumes:
      - ./config:/app/config
      - ./data:/app/data
      - ./models:/app/models
      - ./output:/app/output
    ports:
      - "8000:8000"
    command: poetry run uvicorn src.telco_churn.api:app --host 0.0.0.0 --port 8000

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.15.0
    ports:
      - "5001:5000"
    environment:
      - MLFLOW_TRACKING_URI=http://127.0.0.1:5000
    volumes:
      - ./mlruns:/mlflow/artifacts
      - ./mlflow.db:/mlflow.db  # Ensuring the SQLite database is mounted
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
